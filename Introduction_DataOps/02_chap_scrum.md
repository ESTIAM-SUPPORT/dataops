## **Agilit√© ‚Äì le cadre g√©n√©ral**

L'**Agilit√©** repose sur le **Manifeste Agile (2001)**, qui d√©fend :

* **Les individus** et **leurs interactions**> les processus et outils
* Le logiciel fonctionnel > la documentation exhaustive
* La collaboration avec le client > la n√©gociation contractuelle
* L‚Äôadaptation au changement > le suivi d‚Äôun plan

L'id√©e : livrer **vite, souvent et mieux**, en restant **flexible** face au changement.

---

## **Scrum ‚Äî la m√©thode agile la plus utilis√©e**

**Scrum** n'est pas une m√©thode mais un **cadre (framework)**.
Il est l√©ger, bas√© sur **la transparence**, l'inspection et l'adaptation.

### Les **r√¥les**

* **Product Owner (PO)** : d√©finit les priorit√©s (le 'quoi').
* **Scrum Master** : garantit la m√©thode (le 'comment').
* **Dev Team** : r√©alise le produit (le 'faire').

### Les **artefacts**

* **Product Backlog** : liste des besoins.
* **Sprint Backlog** : s√©lection des t√¢ches pour le sprint.
* **Incr√©ment** : version potentiellement livrable du produit.

### Les **√©v√©nements (rituels)**

1. **Sprint** ‚Üí p√©riode fixe (1 √† 4 semaines).
2. **Sprint Planning** ‚Üí d√©finir ce qu‚Äôon va faire.
3. **Daily Scrum** ‚Üí 15 min chaque jour (synchronisation).
4. **Sprint Review** ‚Üí pr√©sentation du travail fini.
5. **Sprint Retrospective** ‚Üí am√©lioration continue.

### Exemple concret : projet "Pipeline Data ETL pour analyser les performances d‚Äô√©tudiants"

#### **User Stories**

1. **En tant que data engineer**, je veux **collecter les donn√©es depuis Kaggle**, afin de **disposer d'une source de donn√©es brute √† traiter.**
2. **En tant qu'analyste**, je veux **nettoyer et structurer les donn√©es**, afin de **pouvoir g√©n√©rer des statistiques fiables.**
3. **En tant que data scientist**, je veux **entra√Æner un mod√®le pr√©dictif**, afin de **pr√©dire la r√©ussite des √©tudiants.**
4. **En tant que responsable**, je veux **voir un tableau de bord clair**, afin de **suivre la performance globale.**

---

#### **T√¢ches associ√©es (exemple pour la story 1)**

| User Story | T√¢che                                           | R√¥le          |
| ---------- | ----------------------------------------------- | ------------- |
| 1          | Configurer les credentials Kaggle (kaggle.json) | Data Engineer |
| 1          | √âcrire la fonction `extract_from_kaggle()`      | Data Engineer |
| 1          | Tester le t√©l√©chargement avec pytest            | Data Engineer |
| 1          | Stocker le dataset brut dans `/data/raw/`       | Data Engineer |

Et ainsi de suite pour les autres stories (cleaning, transformation, dashboard...).

---

## Exemple de Sprints

###  **Sprint 1 ‚Äî Objectif : Obtenir un dataset propre pr√™t pour analyse**

#### Dur√©e : 1 semaine

#### üë• √âquipe :

* Antoine (Data Engineer)
* Chlo√© (Data Analyst)

---

### **Sprint Backlog**

| **User Story**                                                                                                                     | **T√¢ches techniques**                                                                                                                | **Responsable** | **Statut**  |
| ---------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ | --------------- | ----------- |
| **US1** ‚Äî En tant que data engineer, je veux extraire le dataset depuis Kaggle pour commencer le pipeline.                         | - Cr√©er la fonction `extract_from_kaggle()`  <br> - Configurer la cl√© API dans Docker <br> - √âcrire un test `test_extract_kaggle.py` | Antoine         | ‚úÖ Termin√©   |
| **US2** ‚Äî En tant que data analyst, je veux nettoyer les donn√©es pour supprimer les valeurs manquantes et normaliser les colonnes. | - Impl√©menter `clean_data()` dans `transform.py` <br> - Ajouter des tests unitaires <br> - G√©n√©rer le fichier `clean_students.csv`   | Chlo√©           | üü° En cours |
| **US3** ‚Äî En tant qu‚Äôanalyste, je veux sauvegarder les donn√©es propres dans un dossier versionn√©.                                  | - Cr√©er fonction `load(df, path)` <br> - Ajouter √©tape `run_pipeline.py` <br> - Commit auto via GitHub Actions                       | Antoine         | üî¥ √Ä faire  |

---

### **Colonnes Scrum simplifi√©es (tableau de bord)**

* üü• **To Do** ‚Üí √† planifier ou non commenc√©es
* üü® **In Progress** ‚Üí en d√©veloppement/test
* üü© **Done** ‚Üí valid√©es en revue de code + test√©es

Exemple visuel en texte :

```
To Do         | In Progress       | Done
--------------|-------------------|-------------------
US3 - Load    | US2 - Clean data  | US1 - Extract Kaggle
```

---

###  **Livrables attendus du Sprint**

* `data/clean_students.csv`
* Tests unitaires verts (`pytest`)
* Workflow GitHub Actions fonctionnel

---

**Bilan du Sprint :**

* Extraction ma√Ætris√©e
* Nettoyage √† stabiliser (valeurs nulles dans certaines colonnes)
* √âtape de chargement et automatisation CI/CD √† venir dans le Sprint 2

---

## Gestion des probl√®mes 

### R√©action Agile

1. On en discute lors de la **r√©trospective de sprint** :

   * Qu'est-ce qui a bloqu√© ?
   * Qu'est-ce qu‚Äôon aurait pu faire mieux ?
   * Que change-t-on au prochain sprint ?
2. On ajuste le backlog et le planning (plus court, plus r√©aliste).

> üéØ Objectif : **am√©lioration continue**, pas sanction.
> On apprend √† chaque sprint.

---

## La r√©trospective juste apr√®s la review

### Concr√®tement dans Scrum :

Un **sprint** dure g√©n√©ralement **1 √† 4 semaines** (souvent 2).
L'ordre des √©v√©nements √† la fin du sprint est :

1. **Sprint Review** (revue de sprint)

> L'√©quipe montre ce qu'elle a r√©alis√© au Product Owner et aux parties prenantes.
> ‚Üí Objectif : recueillir du feedback sur le produit.

2. **Sprint Retrospective** (r√©trospective de sprint)

> L'√©quipe (Scrum Master + devs + data engineers, etc.) se r√©unit **entre eux**, sans le client.
> ‚Üí Objectif : r√©fl√©chir **sur la fa√ßon de travailler**, pas sur le produit.

---

###  But de la r√©trospective

R√©pondre √† trois questions simples :

1. Qu‚Äôest-ce qui a bien march√© ?
2. Qu‚Äôest-ce qui a pos√© probl√®me ?
3. Que peut-on am√©liorer pour le prochain sprint ?

Le Scrum Master anime cette r√©union pour qu'elle reste constructive et orient√©e am√©lioration continue.

---

### Dur√©e recommand√©e :

| Dur√©e du sprint | Dur√©e de la r√©trospective |
| --------------- | ------------------------- |
| 1 semaine       | ~45 minutes √† 1 heure     |
| 2 semaines      | ~1h30                     |
| 4 semaines      | ~3 heures                 |

---

### Exemple DataOps :

√Ä la fin d'un sprint :

* **Ce qui a bien march√© :** les tests automatiques du pipeline ont d√©tect√© une erreur t√¥t.
* **Ce qui a pos√© probl√®me :** la connexion Kaggle a souvent √©chou√©.
* **√Ä am√©liorer :** ajouter un *retry automatique* dans l‚Äô√©tape `extract_from_kaggle`.

> La conclusion devient une **t√¢che d‚Äôam√©lioration** pour le sprint suivant.


## Estimation des difficult√©es de chaque useer story ou t√¢che √† r√©aliser 

En Scrum (et plus largement dans l'agilit√©), la difficult√© des t√¢ches est **estim√©e par l‚Äô√©quipe**, pas par le chef de projet.

##  1. Le but

Attribuer une **valeur de complexit√©** (ou d'effort) √† chaque **user story** ou **t√¢che**, pour :

* anticiper la charge de travail,
* √©quilibrer le sprint,
* et suivre la *v√©locit√©* (la capacit√© moyenne de l‚Äô√©quipe par sprint).

---

## 2. L'unit√© : les *Story Points*

Les t√¢ches ne sont pas estim√©es en heures mais en **points d‚Äôeffort** (Story Points), qui mesurent la **complexit√© globale** :

> effort ‚ü∂ temps ‚ü∂ incertitude ‚ü∂ risque technique

Par exemple (suite de Fibonacci)

| Story Points | Signification                                 |
| ------------ | --------------------------------------------- |
| 1            | Tr√®s simple (changement mineur, script court) |
| 2            | Simple (une fonction √† √©crire)                |
| 3            | Moyenne complexit√©                            |
| 5            | Difficile, plusieurs √©tapes                   |
| 8            | Tr√®s complexe                                 |
| 13+          | Trop gros ‚Üí √† d√©couper                        |

On utilise souvent la **suite de Fibonacci** : 1, 2, 3, 5, 8, 13, 21‚Ä¶
‚Üí car les grands nombres refl√®tent une incertitude croissante.

---

## 3. M√©thode : *Planning Poker*

C'est la m√©thode la plus utilis√©e 

### D√©roulement :

1. Le Product Owner pr√©sente la user story.
2. Chaque membre estime individuellement la difficult√©, sans montrer son estimation aux autres (avec des cartes ou outils num√©riques : 1, 2, 3, 5, 8‚Ä¶).
3. Tout le monde r√©v√®le sa carte **en m√™me temps**.
4. Si les estimations diff√®rent, on discute pour comprendre pourquoi.
5. L'√©quipe converge vers une estimation commune.

> Ce n'est **pas un vote**, c'est un **consensus collectif**.

---

## 4. Exemple concret DataOps

User story :

> ‚ÄúEn tant que Data Engineer, je veux automatiser le t√©l√©chargement des datasets Kaggle pour simplifier l'int√©gration.‚Äù

√âquipe :

* Alice (backend) ‚Üí 3 points
* Bob (infra) ‚Üí 5 points
* Chlo√© (analyste) ‚Üí 3 points

Discussion ‚Üí Bob explique les difficult√©s r√©seau possibles et la gestion d'erreurs ‚Üí on s'aligne sur **5 points**.

---

## 5. Pourquoi c‚Äôest important

* Favorise la **communication technique** et la **vision partag√©e**.
* Permet d'√©valuer la **v√©locit√© moyenne** (ex. : ‚Äúon livre ~20 points par sprint‚Äù).
* Aide √† **planifier le prochain sprint** de mani√®re r√©aliste.

